{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Basics.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwqdbT1oMCZE"
      },
      "source": [
        "## NLP Basics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8kyPvyjN_FY"
      },
      "source": [
        "### Loading the dataset\n",
        "In this notebook we are working on an emotion classification task. The dataset contains tweets labeled into 6 categories.\n",
        "\n",
        "First, let's load the libraries and a few utility functions that we will use to help load our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THuly31cMziw",
        "outputId": "2287fea8-f466-479c-b806-c46e99b9eb6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## import torch \n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import torch.nn as nn\n",
        "\n",
        "## import other important libraries and functions\n",
        "import pickle\n",
        "\n",
        "## function to convert file to pickle format\n",
        "def convert_to_pickle(item, directory):\n",
        "    pickle.dump(item, open(directory,\"wb\"))\n",
        "\n",
        "## funtion to load pickle file\n",
        "def load_from_pickle(directory):\n",
        "    return pickle.load(open(directory,\"rb\"))\n",
        "\n",
        "print(torch.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEsWTSd6wQC_"
      },
      "source": [
        "Download the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0M1T5Zw0JMO-",
        "outputId": "2eb4e67a-2a0c-4291-9794-f04f563d2087",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "!wget https://www.dropbox.com/s/607ptdakxuh5i4s/merged_training.pkl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-14 12:54:27--  https://www.dropbox.com/s/607ptdakxuh5i4s/merged_training.pkl\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.1, 2620:100:6021:1::a27d:4101\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/607ptdakxuh5i4s/merged_training.pkl [following]\n",
            "--2020-04-14 12:54:28--  https://www.dropbox.com/s/raw/607ptdakxuh5i4s/merged_training.pkl\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc63dfb651602b81941c473a950d.dl.dropboxusercontent.com/cd/0/inline/A13XlDQTwN9D4eeqYmU9uaZGazRXGj0KZDCI-bjef5k8JA-shd81CSea7WSxTVuGJ1TQEpmWh-43k3zAyP4Bl_u4K35z3MHnuu13K2TGOWv-RM_ES_RwIFGRPPOT6ut_sgk/file# [following]\n",
            "--2020-04-14 12:54:28--  https://uc63dfb651602b81941c473a950d.dl.dropboxusercontent.com/cd/0/inline/A13XlDQTwN9D4eeqYmU9uaZGazRXGj0KZDCI-bjef5k8JA-shd81CSea7WSxTVuGJ1TQEpmWh-43k3zAyP4Bl_u4K35z3MHnuu13K2TGOWv-RM_ES_RwIFGRPPOT6ut_sgk/file\n",
            "Resolving uc63dfb651602b81941c473a950d.dl.dropboxusercontent.com (uc63dfb651602b81941c473a950d.dl.dropboxusercontent.com)... 162.125.65.6, 2620:100:6021:6::a27d:4106\n",
            "Connecting to uc63dfb651602b81941c473a950d.dl.dropboxusercontent.com (uc63dfb651602b81941c473a950d.dl.dropboxusercontent.com)|162.125.65.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: /cd/0/inline2/A10p4A6Kv5hsGgVMktMp7BdkHc-Iv43Z7Cch50merXUTEwfc1ZJbc4VTFD_-clcsA2qlH06GQFT1uD3pa33dhOWU-s1_GfnyTdMB8J8AD3Hz0S6V7DiMFb4jjMDZhXMEYpqket46MffPYRrPEJUgLrPBHoNntDNH90JoICFzZLrtW-xbnrn-23K7mRiqA0sfhmgMmbXp6m5mcKQCHc1WsOjpUM83vfzWqn9nB4O6UZy1kBef3JArOXj-9XCvpaQODSFXmMOs5-1WptQYIRLFv8SoaGI3n2AEnLNDZRNY5lFa642nEsTnpf_wgGDsxYyImWmrHLJQQv1xx_Izsxv0dhlrUKFnPmoBoVntLZKVT0DZFQ/file [following]\n",
            "--2020-04-14 12:54:29--  https://uc63dfb651602b81941c473a950d.dl.dropboxusercontent.com/cd/0/inline2/A10p4A6Kv5hsGgVMktMp7BdkHc-Iv43Z7Cch50merXUTEwfc1ZJbc4VTFD_-clcsA2qlH06GQFT1uD3pa33dhOWU-s1_GfnyTdMB8J8AD3Hz0S6V7DiMFb4jjMDZhXMEYpqket46MffPYRrPEJUgLrPBHoNntDNH90JoICFzZLrtW-xbnrn-23K7mRiqA0sfhmgMmbXp6m5mcKQCHc1WsOjpUM83vfzWqn9nB4O6UZy1kBef3JArOXj-9XCvpaQODSFXmMOs5-1WptQYIRLFv8SoaGI3n2AEnLNDZRNY5lFa642nEsTnpf_wgGDsxYyImWmrHLJQQv1xx_Izsxv0dhlrUKFnPmoBoVntLZKVT0DZFQ/file\n",
            "Reusing existing connection to uc63dfb651602b81941c473a950d.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49991846 (48M) [application/octet-stream]\n",
            "Saving to: ‘merged_training.pkl’\n",
            "\n",
            "merged_training.pkl 100%[===================>]  47.68M  64.4MB/s    in 0.7s    \n",
            "\n",
            "2020-04-14 12:54:30 (64.4 MB/s) - ‘merged_training.pkl’ saved [49991846/49991846]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6P9vJ5Qirqrb",
        "outputId": "ce7ab09a-fc11-44e7-f38d-441be19f2606",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "## load the data\n",
        "## note we are using the utility function we defined above\n",
        "\n",
        "data = load_from_pickle(directory=\"merged_training.pkl\")\n",
        "data.emotions.value_counts().plot.bar()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f78ad9b6198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEOu4o6QxAP2"
      },
      "source": [
        "After a quick glance at the data you will see that it is already preprocessed. Preprocessing is based on my papers which you can find [here](https://www.aclweb.org/anthology/D18-1404/). If you used this data for research purposes, please considering citing the paper:\n",
        "\n",
        "```json\n",
        "@inproceedings{saravia-etal-2018-carer,\n",
        "    title = \"{CARER}: Contextualized Affect Representations for Emotion Recognition\",\n",
        "    author = \"Saravia, Elvis  and\n",
        "      Liu, Hsien-Chi Toby  and\n",
        "      Huang, Yen-Hao  and\n",
        "      Wu, Junlin  and\n",
        "      Chen, Yi-Shin\",\n",
        "    booktitle = \"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing\"\n",
        "    year = \"2018\",\n",
        "    address = \"Brussels, Belgium\",\n",
        "    publisher = \"Association for Computational Linguistics\",\n",
        "    url = \"https://www.aclweb.org/anthology/D18-1404\",\n",
        "    doi = \"10.18653/v1/D18-1404\",\n",
        "    pages = \"3687--3697\"\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNPzFux_y5C8",
        "outputId": "8847045c-2c37-4ee3-ecd5-0d6695e96c5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "416809"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKDg-XVysVVI",
        "outputId": "9212f236-4534-400d-f16d-c4698adbfc04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "## preview the first 10 docs\n",
        "data.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emotions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>27383</th>\n",
              "      <td>i feel awful about it too because it s my job ...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110083</th>\n",
              "      <td>im alone i feel awful</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140764</th>\n",
              "      <td>ive probably mentioned this before but i reall...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100071</th>\n",
              "      <td>i was feeling a little low few days back</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2837</th>\n",
              "      <td>i beleive that i am much more sensitive to oth...</td>\n",
              "      <td>love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18231</th>\n",
              "      <td>i find myself frustrated with christians becau...</td>\n",
              "      <td>love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10714</th>\n",
              "      <td>i am one of those people who feels like going ...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35177</th>\n",
              "      <td>i feel especially pleased about this as this h...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122177</th>\n",
              "      <td>i was struggling with these awful feelings and...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26723</th>\n",
              "      <td>i feel so enraged but helpless at the same time</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text emotions\n",
              "27383   i feel awful about it too because it s my job ...  sadness\n",
              "110083                              im alone i feel awful  sadness\n",
              "140764  ive probably mentioned this before but i reall...      joy\n",
              "100071           i was feeling a little low few days back  sadness\n",
              "2837    i beleive that i am much more sensitive to oth...     love\n",
              "18231   i find myself frustrated with christians becau...     love\n",
              "10714   i am one of those people who feels like going ...      joy\n",
              "35177   i feel especially pleased about this as this h...      joy\n",
              "122177  i was struggling with these awful feelings and...      joy\n",
              "26723     i feel so enraged but helpless at the same time    anger"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KklIDotNsa0i"
      },
      "source": [
        "## Tokenizing and Sampling\n",
        "In the next steps we are going to **tokenize** our pieces of text, create index mapping for words, and also construct a vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00VAgTFSuKHN",
        "outputId": "716c8b8b-c720-4509-c353-b385bac173db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "## retain only text that contain less that 70 tokens to avoid too much padding\n",
        "data[\"token_size\"] = data[\"text\"].apply(lambda x: len(x.split(' ')))\n",
        "data = data.loc[data['token_size'] < 70].copy()\n",
        "\n",
        "## sampling; we don't need to use the entire data as we only want to show you\n",
        "## the tokenization/batch preparation process\n",
        "data = data.sample(n=50000);\n",
        "\n",
        "print(data.head(10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                     text emotions  token_size\n",
            "34736   i start to lose that sense of independence in ...     fear          19\n",
            "26622   i feel as if they are talking bad about me beh...  sadness          13\n",
            "38867                i feel honoured to be your companion      joy           7\n",
            "21834   i didnt feel pressure to be perfect and i didn...      joy          18\n",
            "32713   im feeling quite nostalgic today as if the onl...     love          44\n",
            "103307  i was positively giddy when the kids left this...  sadness          26\n",
            "36268                        i feel fine and no labor yet      joy           7\n",
            "57010   ive fallen into the fickle feeling trap that i...    anger          21\n",
            "71172   i have let go of those silly qualities and hav...  sadness          30\n",
            "47812   i feel numb to the anguish that is being repea...  sadness          17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vo6WRUcdsGt_"
      },
      "source": [
        "### Building Vocabulary\n",
        "After tokenizing text, it's time to build the vocabulary, which is used to determine the features that we will be using to train the models.\n",
        "\n",
        "The code below takes create of creating the vocabulary. The code you see below is standard code you will see in many tutorials. Take some time to understand the intuition behind it.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqcA6SwysfrZ"
      },
      "source": [
        "## This class creates a word -> index mapping (e.g,. \"dad\" -> 5) and vice-versa \n",
        "## (e.g., 5 -> \"dad\") for the dataset\n",
        "class ConstructVocab():\n",
        "    def __init__(self, sentences):\n",
        "        self.sentences = sentences\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.vocab = set()\n",
        "        self.create_index()\n",
        "        \n",
        "    def create_index(self):\n",
        "        for s in self.sentences:\n",
        "            # update with individual tokens\n",
        "            self.vocab.update(s.split(' '))\n",
        "            \n",
        "        # sort the vocab\n",
        "        self.vocab = sorted(self.vocab)\n",
        "\n",
        "        # add a padding token with index 0\n",
        "        self.word2idx['<pad>'] = 0\n",
        "        \n",
        "        # word to index mapping\n",
        "        for index, word in enumerate(self.vocab):\n",
        "            self.word2idx[word] = index + 1 # +1 because of pad token\n",
        "        \n",
        "        # index to word mapping\n",
        "        for word, index in self.word2idx.items():\n",
        "            self.idx2word[index] = word  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dydcpAItEFY",
        "outputId": "21f1fc3f-0334-4468-a964-d4a41dffa929",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "## construct vocab and indexing\n",
        "inputs = ConstructVocab(data[\"text\"].values.tolist())\n",
        "\n",
        "## examples of what is in the vocab\n",
        "inputs.vocab[0:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'aa',\n",
              " 'aaa',\n",
              " 'aaaa',\n",
              " 'aaand',\n",
              " 'aaawesome',\n",
              " 'aactually',\n",
              " 'aaron',\n",
              " 'aaryn',\n",
              " 'ab']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noJhZ7uW8-Yi",
        "outputId": "2fc8e6e6-6855-4e94-890e-6f4b366128d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## obtain id of token\n",
        "inputs.word2idx['a']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uakzZovn9PfF",
        "outputId": "db1b996e-579d-4643-bffc-9f797f1aa84b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## you can do the reverse now -- obtain the token via the id\n",
        "inputs.idx2word[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'a'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmBNdiaOtCx8"
      },
      "source": [
        "### Converting Data Into Tensors\n",
        "Now that we have created our vocab, we can now try to convert the text input into a tensor format, which inolves a vectorization processing using those vocab ids defined above.\n",
        "\n",
        "Let's try:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv7I8IxwtgvH"
      },
      "source": [
        "## vectorize to tensor\n",
        "input_tensor = [[inputs.word2idx[s] for s in es.split(' ')]  for es in data[\"text\"].values.tolist()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSz-Fk9nu_3L",
        "outputId": "75d865e4-4b34-42d3-bfb3-f4cf8d7572d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "## examples of what is in the input tensors\n",
        "input_tensor[0:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[11658,\n",
              "  22968,\n",
              "  24644,\n",
              "  14242,\n",
              "  24282,\n",
              "  21334,\n",
              "  16663,\n",
              "  12059,\n",
              "  11951,\n",
              "  24282,\n",
              "  11658,\n",
              "  8746,\n",
              "  1,\n",
              "  14252,\n",
              "  15583,\n",
              "  11106,\n",
              "  24644,\n",
              "  6896,\n",
              "  24370],\n",
              " [11658,\n",
              "  8746,\n",
              "  1308,\n",
              "  11725,\n",
              "  24352,\n",
              "  1198,\n",
              "  23938,\n",
              "  1749,\n",
              "  61,\n",
              "  14877,\n",
              "  2145,\n",
              "  15861,\n",
              "  1718]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5JKHBU3AD6K"
      },
      "source": [
        "---\n",
        "### EXCERCISE - Obtaining Tensor Representation\n",
        "\n",
        "Convert the following sentences into their corresponding tensor representations. \n",
        "\n",
        "In addition, try to combine/merge the representations into one tensor.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPviFVESAboT"
      },
      "source": [
        "sent1 = \"Hello! how is everthing doing?\"\n",
        "sent2 = \"I am doing okay\"\n",
        "\n",
        "### YOUR CODE HERE\n",
        "\n",
        "### YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XE177iRu0JP7"
      },
      "source": [
        "### Padding Data\n",
        "In order to train our recurrent neural network (RNN) model for text classification (prsented in the next notebook), we require some type of padding to generate inputs of same length. RNNs expect inputs of same lenght."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wX-3r5bG0OUI"
      },
      "source": [
        "## function to find max lenght of batch\n",
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkabN8w30Q1U",
        "outputId": "b171529a-0bf7-4b0f-ca5f-73dd75c477ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## calculate the max_length of input tensor\n",
        "max_length_inp = max_length(input_tensor)\n",
        "print(max_length_inp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "69\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcoGiba20TvZ"
      },
      "source": [
        "## padding sequences\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def pad_sequences(x, max_len):\n",
        "    padded = np.zeros((max_len), dtype=np.int64)\n",
        "    if len(x) > max_len: padded[:] = x[:max_len]\n",
        "    else: padded[:len(x)] = x\n",
        "    return padded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDN-PU-i0VVM"
      },
      "source": [
        "## inplace padding\n",
        "input_tensor = [pad_sequences(x, max_length_inp) for x in input_tensor]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6nGnvvABES2"
      },
      "source": [
        "---\n",
        "### EXERCISE\n",
        "\n",
        "Pad the tensor you created in the previous exercise for `sent1` and `sent2`.\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRum83KN0cqP",
        "outputId": "5d4ec330-bc8a-45c6-d0c5-135ee46e4e59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "## check padded sequences for first two examples\n",
        "input_tensor[0:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([11658, 22968, 24644, 14242, 24282, 21334, 16663, 12059, 11951,\n",
              "        24282, 11658,  8746,     1, 14252, 15583, 11106, 24644,  6896,\n",
              "        24370,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0]),\n",
              " array([11658,  8746,  1308, 11725, 24352,  1198, 23938,  1749,    61,\n",
              "        14877,  2145, 15861,  1718,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cg0jfvUw0ft6"
      },
      "source": [
        "### Binarization\n",
        "We would like to binarize our `target` values in our dataset so that we can obtain `one-hot encodings` for the target values. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eneDYVk0emN"
      },
      "source": [
        "import time\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import itertools\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "## convert targets to one-hot encoding vectors\n",
        "emotions = list(set(data.emotions.unique()))\n",
        "num_emotions = len(emotions)\n",
        "\n",
        "## binarizer\n",
        "mlb = preprocessing.MultiLabelBinarizer()\n",
        "data_labels =  [set(emos) & set(emotions) for emos in data[['emotions']].values]\n",
        "bin_emotions = mlb.fit_transform(data_labels)\n",
        "target_tensor = np.array(bin_emotions.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXKs54VU02-a",
        "outputId": "4d2fa714-4da7-4b15-8de0-4086dfe6a26e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "## print the one-hot encodings for the first two examples in the dataset\n",
        "target_tensor[0:2] "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 1, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0D6n29607e6",
        "outputId": "9172c2bb-6318-443f-f68f-c0006f3f2d2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "## we can easily check the original values for the first two piece of text\n",
        "data[0:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emotions</th>\n",
              "      <th>token_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>34736</th>\n",
              "      <td>i start to lose that sense of independence in ...</td>\n",
              "      <td>fear</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26622</th>\n",
              "      <td>i feel as if they are talking bad about me beh...</td>\n",
              "      <td>sadness</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text emotions  token_size\n",
              "34736  i start to lose that sense of independence in ...     fear          19\n",
              "26622  i feel as if they are talking bad about me beh...  sadness          13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeTtZBzL0-ew",
        "outputId": "d479f3a1-d3a0-4ac5-fa04-037cca04252a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## we can easily find the emotion index for instance of the first example above: fear\n",
        "get_emotion = lambda t: np.argmax(t)\n",
        "get_emotion(target_tensor[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se7sspEn1Dw1",
        "outputId": "3a262180-c125-42e5-ef85-342105d33fb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## pass that index to a key/value object to obtain the original emotion \n",
        "emotion_dict = {0: 'anger', 1: 'fear', 2: 'joy', 3: 'love', 4: 'sadness', 5: 'surprise'}\n",
        "emotion_dict[get_emotion(target_tensor[0])]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'fear'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dvn5kjn1KKg"
      },
      "source": [
        "### Split Data\n",
        "\n",
        "We would like to split our data into a train and validation set. In addition, we also want a holdout dataset (test set) for evaluating the models.\n",
        "\n",
        "Let's do that below. We are going to use the built in `train_test_split` dataset from scikit learn. Let's do that below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Th4wBMUR1YuR",
        "outputId": "159b70af-98e7-4f99-b610-d1811a5cbe0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "## Split the validataion further to obtain a holdout dataset (for testing) -- split 50:50\n",
        "input_tensor_val, input_tensor_test, target_tensor_val, target_tensor_test = train_test_split(input_tensor_val, target_tensor_val, test_size=0.5)\n",
        "\n",
        "## Show length\n",
        "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val), len(input_tensor_test), len(target_tensor_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40000, 40000, 5000, 5000, 5000, 5000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rb80PJb11_it"
      },
      "source": [
        "### Dataset and Data Loader\n",
        "\n",
        "We can also load the data into a PyTorch `DataLoader` object, which makes it easy to manipulate the data, create batches, and apply further transformations. This simplified our training procedure as well -- we will look a this in the next notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vy8lEQMH2dsr"
      },
      "source": [
        "## Define a few useful parameters\n",
        "\n",
        "TRAIN_BUFFER_SIZE = len(input_tensor_train)\n",
        "VAL_BUFFER_SIZE = len(input_tensor_val)\n",
        "TEST_BUFFER_SIZE = len(input_tensor_test)\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "TRAIN_N_BATCH = TRAIN_BUFFER_SIZE // BATCH_SIZE\n",
        "VAL_N_BATCH = VAL_BUFFER_SIZE // BATCH_SIZE\n",
        "TEST_N_BATCH = TEST_BUFFER_SIZE // BATCH_SIZE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MV3LfSO228HT"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7nEtXXsZPqy"
      },
      "source": [
        "We use the `Dataset` class to represent a dataset object. You override a few methods and you should be able to create the dataset object you need."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDt9fCs53Tcg"
      },
      "source": [
        "class MyData(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.data = X\n",
        "        self.target = y\n",
        "        self.length = [ np.sum(1 - np.equal(x, 0)) for x in X]\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index]\n",
        "        x_len = self.length[index]\n",
        "        return x, y, x_len\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8Y21Kt1aN4A"
      },
      "source": [
        "Load the data and then pass it to an `iterator` called `DataLoadder` which finally defines how samples/batches should be prepared."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLYJMrGM3wgZ"
      },
      "source": [
        "## Dataset instance\n",
        "train_dataset = MyData(input_tensor_train, target_tensor_train)\n",
        "val_dataset = MyData(input_tensor_val, target_tensor_val)\n",
        "test_dataset = MyData(input_tensor_test, target_tensor_test)\n",
        "\n",
        "\n",
        "## Data Loader instance\n",
        "train_dataset = DataLoader(train_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)\n",
        "\n",
        "val_dataset = DataLoader(val_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)\n",
        "\n",
        "test_dataset = DataLoader(test_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV8ttR8BBV58",
        "outputId": "283c7944-c4ba-4fcd-9b94-28d5a1086730",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "val_dataset.batch_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNMbPgVr4ZZ_",
        "outputId": "f7e960cb-81b9-4f1e-c681-af96fc29c07d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "## preview of the data\n",
        "val_dataset.dataset.data[0:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([11799,  8753, 22354, 18123, 26880, 15861,  7518,   873,  1308,\n",
              "        11658, 10113, 24644, 22103, 16768, 25140, 16266, 11658, 13397,\n",
              "        24282, 26633, 11658, 11371, 16768, 24292, 20947, 16768, 26538,\n",
              "        15597, 11799, 10143, 24644, 21234,  1448, 13741,     1, 13289,\n",
              "        14249,  9284, 24292, 26543,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0]),\n",
              " array([11658,  8746, 13956, 11658, 10867, 13098, 26924, 25764,  9558,\n",
              "            1,  7140,   873,   745,  1509, 24644, 19908, 24292,  6341,\n",
              "        16663, 12690,  8199,  1308, 12690, 10737,  8707, 24282, 22202,\n",
              "         6341,  1198,  9934, 14251,   873, 24561, 12647,  9934, 16353,\n",
              "        21380,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    }
  ]
}